{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Found 42500 images belonging to 13 classes.\n",
      "Number of images found: 42500\n",
      "Number of classes found: 13\n",
      "   2/1329 [..............................] - ETA: 39:19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  24/1329 [..............................] - ETA: 48:20"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3182: DecompressionBombWarning: Image size (96714256 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110/1329 [========================>.....] - ETA: 6:18"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1329/1329 [==============================] - 2277s 2s/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "# Directory where your images are located\n",
    "dataset_dir = r\"D:\\SEM-4\\PROJECTS\\ML\\Archive\"\n",
    "\n",
    "# Initialize VGG16 model, this time including the top layers\n",
    "base_model = VGG16(include_top=True, weights='imagenet')\n",
    "\n",
    "# However, instead of using the model as is, create a new model that outputs the features from the penultimate layer\n",
    "# The penultimate layer is the one before the final classification layer, and it has 4096 features\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)\n",
    "\n",
    "# Create an instance of the ImageDataGenerator for loading images\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Create a data generator for reading images from directories\n",
    "generator = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,  # Adjust based on your GPU memory\n",
    "    class_mode='sparse',  # 'sparse' yields integer labels\n",
    "    shuffle=False  # Important for keeping labels in order\n",
    ")\n",
    "\n",
    "# Number of images and labels\n",
    "num_images = generator.samples\n",
    "print(\"Number of images found:\", num_images)\n",
    "num_classes = generator.num_classes\n",
    "print(\"Number of classes found:\", num_classes)\n",
    "\n",
    "# Extract features\n",
    "features = model.predict(generator, steps=np.ceil(num_images/32), verbose=1)\n",
    "\n",
    "# Get the labels (ensure they are in the same order as the images)\n",
    "labels = generator.classes\n",
    "\n",
    "# Saving features and labels to .npy files\n",
    "np.save('features_4096.npy', features)\n",
    "np.save('labels_4096.npy', labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 4096)\n",
      "(42500,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "features = np.load(r'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\features_4096.npy')\n",
    "size = np.shape(features)\n",
    "print(size)\n",
    "\n",
    "labels = np.load(r'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy')\n",
    "size1 = np.shape(labels)\n",
    "print(size1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'n_neighbors': 15}\n",
      "Best accuracy found:  0.5213823529411765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.38      0.45       276\n",
      "           1       0.77      0.46      0.58       646\n",
      "           2       0.39      0.66      0.49      1081\n",
      "           3       0.63      0.45      0.53       506\n",
      "           4       0.69      0.63      0.66       448\n",
      "           5       0.60      0.61      0.60       594\n",
      "           6       0.94      0.31      0.47       269\n",
      "           7       0.48      0.61      0.54      1088\n",
      "           8       0.60      0.57      0.58      1204\n",
      "           9       0.33      0.54      0.41       498\n",
      "          10       0.61      0.49      0.55      1352\n",
      "          11       0.42      0.12      0.18       318\n",
      "          12       0.88      0.65      0.75       220\n",
      "\n",
      "    accuracy                           0.53      8500\n",
      "   macro avg       0.61      0.50      0.52      8500\n",
      "weighted avg       0.57      0.53      0.53      8500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming features and labels are already loaded from the .npy files\n",
    "features = np.load('D://SEM-4//ML//CODES\\Machine-Learning//features_4096.npy')\n",
    "labels = np.load('D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy')\n",
    "\n",
    "# Reshape features for kNN\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid: number of neighbors\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15]}\n",
    "\n",
    "# Initialize a kNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit it to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best accuracy found: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate on the test set with the best parameters\n",
    "best_knn = grid_search.best_estimator_\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 1305\n",
      "Class 1: 3035\n",
      "Class 2: 5312\n",
      "Class 3: 2607\n",
      "Class 4: 2235\n",
      "Class 5: 3115\n",
      "Class 6: 1324\n",
      "Class 7: 5373\n",
      "Class 8: 6192\n",
      "Class 9: 2521\n",
      "Class 10: 6813\n",
      "Class 11: 1510\n",
      "Class 12: 1158\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load your labels if not already loaded\n",
    "labels = np.load('D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy')\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "\n",
    "# Printing each class with its count on a new line\n",
    "for class_label, count in class_distribution.items():\n",
    "    print(f\"Class {class_label}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Performance Metrics:\n",
      "Accuracy: 0.59\n",
      "Precision: 0.59\n",
      "Recall: 0.59\n",
      "F1 Score: 0.58\n",
      "Confusion Matrix:\n",
      "[[ 158    6   36    5    8   16    0   38   51   20   64    2    4]\n",
      " [   6  587   11   51   63   17   14   36   66    5   61    9   10]\n",
      " [  10   14  942   13    2   28    9  106  244   73  180    7    0]\n",
      " [   1   46   24  442   30   14   19   49   60    2   47   17    9]\n",
      " [   2   58    2   24  497    5    8   21   26    2   23    5    2]\n",
      " [  17   28   85    5    3  516    4   14   84   52   89    3    1]\n",
      " [   0   23   12   32   11    6  215   22   39    0   21    6    3]\n",
      " [   9   16  112   28   12   20    6 1009   79   29  265    7    4]\n",
      " [   6   39  231   35   14   36    9   58 1306   26   61   11   30]\n",
      " [  16    8  148    5    2   28    1   39   74  302  113    1    1]\n",
      " [  24   36  150   26    4   54   10  247  179   69 1220   18    8]\n",
      " [   2   19   36   42   16   14    9  112   86    3   58   73    7]\n",
      " [   0   13    2   12    1    0    2    1   54    0    6    2  241]]\n",
      "\n",
      "\n",
      "XGBoost Performance Metrics:\n",
      "Accuracy: 0.58\n",
      "Precision: 0.59\n",
      "Recall: 0.58\n",
      "F1 Score: 0.58\n",
      "Confusion Matrix:\n",
      "[[ 136    0   49    3    3   15    0   44   53   15   84    3    3]\n",
      " [   2  565   17   43   48   15   12   47   72    5   93    8    9]\n",
      " [   8   11  971   14    3   30    4  102  217   73  187    7    1]\n",
      " [   0   44   27  433   16   12   11   45   84    1   67   16    4]\n",
      " [   3   67    4   21  487    8    3   22   22    0   29    8    1]\n",
      " [  11   17   86    6    1  515    1   24   95   43  100    2    0]\n",
      " [   0   33   12   28    9    5  189   26   49    0   31    7    1]\n",
      " [   6    9  134   19    5   21    5 1000   83   28  273   10    3]\n",
      " [   3   25  258   29   13   24    3   64 1289   20  106   11   17]\n",
      " [  10    7  163    4    3   38    0   37   75  289  110    2    0]\n",
      " [  17   23  161   13    7   37    3  262  190   66 1248   10    8]\n",
      " [   5   16   35   32    7   15    4  104   95    3   91   65    5]\n",
      " [   0   10    3   14    2    1    1    4   61    0    7    2  229]]\n",
      "\n",
      "\n",
      "SVM Performance Metrics:\n",
      "Accuracy: 0.64\n",
      "Precision: 0.64\n",
      "Recall: 0.64\n",
      "F1 Score: 0.63\n",
      "Confusion Matrix:\n",
      "[[ 158    6   41    5    6   12    0   47   45   26   56    4    2]\n",
      " [   3  636   16   51   42    9   10   38   50    4   60    9    8]\n",
      " [  10   14 1039    7    3   15    5   97  208   62  167    1    0]\n",
      " [   1   37   24  498   20   11   14   47   55    1   37   11    4]\n",
      " [   2   56    4   26  516    2    6   21   17    0   22    3    0]\n",
      " [  15   23   76    7    1  533    1   18   78   67   78    3    1]\n",
      " [   0   18   11   31    8    3  244   20   32    1   17    4    1]\n",
      " [  12   12  108   23    9   15    5 1095   64   23  221    7    2]\n",
      " [   3   31  212   28   14   24    4   55 1387   19   58    8   19]\n",
      " [  13    5  136    3    2   18    0   33   69  353  105    1    0]\n",
      " [  18   29  128   30    6   28    7  246  161   75 1302   12    3]\n",
      " [   4   21   32   42    9    7    9  109   85    2   63   87    7]\n",
      " [   0   14    4   12    3    0    0    2   41    0    4    0  254]]\n",
      "\n",
      "\n",
      "Random Forest Performance Metrics:\n",
      "Accuracy: 0.52\n",
      "Precision: 0.57\n",
      "Recall: 0.52\n",
      "F1 Score: 0.50\n",
      "Confusion Matrix:\n",
      "[[  73    4   85    1    4    4    0   42  100   29   65    0    1]\n",
      " [   0  544   21   30   58   10    0   39  125    3  101    0    5]\n",
      " [   3   12  923    5    4   24    1  107  279   42  226    0    2]\n",
      " [   0   71   36  300   35   16    1   60  159    1   79    0    2]\n",
      " [   0   68    6   27  452    8    0   32   39    2   39    0    2]\n",
      " [   7   36  113    1    3  442    0   21  130   43  105    0    0]\n",
      " [   0   31   29   40   15    3   84   46   96    0   44    0    2]\n",
      " [   0   13  153    9    9   20    0  933  115   31  312    0    1]\n",
      " [   0   51  283   29   13   30    0   59 1271   14  103    0    9]\n",
      " [   4    9  237    0    1   15    0   34  115  206  116    0    1]\n",
      " [   5   34  221    8   10   36    1  230  254   57 1187    0    2]\n",
      " [   2   21   40   24    6    9    0  119  136    1  117    1    1]\n",
      " [   0   21    1   11    3    0    0    2  104    0    6    0  186]]\n",
      "\n",
      "\n",
      "AdaBoost Performance Metrics:\n",
      "Accuracy: 0.29\n",
      "Precision: 0.28\n",
      "Recall: 0.29\n",
      "F1 Score: 0.27\n",
      "Confusion Matrix:\n",
      "[[  5  13 189   4  11  11   2  50  71  24  22   0   6]\n",
      " [  2 323  76  42 147  58  22  38 109   3  56   0  60]\n",
      " [  7  61 785  25  28  50  10 172 231  75 161   0  23]\n",
      " [  2  85  63 135 101  34  36  65 124   8  49   0  58]\n",
      " [  0 127  17  60 291  16  17  52  37   1  29   0  28]\n",
      " [  4 104 186  17  58 168   6  56 130  28 125   0  19]\n",
      " [  0  40  32  33  48  16  41  41  68   5  36   1  29]\n",
      " [ 11  49 340  40  48  48  11 561 125  31 323   1   8]\n",
      " [  5 117 482  61  62  74  23 139 566  69  98   2 164]\n",
      " [  4  11 381   9  18  18   9  60  95  73  51   0   9]\n",
      " [  4  98 438  31  61  81  14 553 212  45 485   2  21]\n",
      " [  4  25  98  25  33  21   9 108  83   8  47   2  14]\n",
      " [  0   8   1  11   6   8   1   1  43   2  17   1 235]]\n",
      "\n",
      "\n",
      "Decision Tree Performance Metrics:\n",
      "Accuracy: 0.30\n",
      "Precision: 0.30\n",
      "Recall: 0.30\n",
      "F1 Score: 0.30\n",
      "Confusion Matrix:\n",
      "[[ 54  17  48  14  16  28   7  47  64  36  58  16   3]\n",
      " [ 10 299  41  97 105  60  34  46  87  22  85  25  25]\n",
      " [ 48  38 451  55  21  99  22 187 255 152 238  44  18]\n",
      " [ 18  64  60 190  49  23  33  70  98  27  61  42  25]\n",
      " [  3  96  22  55 277  29  20  43  48   9  43  16  14]\n",
      " [ 31  44 112  28  15 287  19  56 100  62 121  20   6]\n",
      " [ 12  31  31  41  19  18  76  41  46   9  40  14  12]\n",
      " [ 33  56 160  65  29  73  39 569 121  66 309  63  13]\n",
      " [ 68  96 257  92  42 100  39 121 650 105 164  72  56]\n",
      " [ 35   9 169  16   6  66  11  66  87 156  92  13  12]\n",
      " [ 49  79 224  86  37 121  43 294 177 115 736  67  17]\n",
      " [ 13  26  50  44  19  28  17  84  66  17  64  37  12]\n",
      " [  4  24  17  30  14  19   8  17  57   4  20  14 106]]\n",
      "\n",
      "\n",
      "Naive Bayes Performance Metrics:\n",
      "Accuracy: 0.39\n",
      "Precision: 0.44\n",
      "Recall: 0.39\n",
      "F1 Score: 0.38\n",
      "Confusion Matrix:\n",
      "[[225   9  20   1  10   9   3  21  21  62   5  15   7]\n",
      " [ 34 341  10  29 221  50  41  39  40   6  30  28  67]\n",
      " [116  19 547  25  49  69  36 159 103 328 101  37  39]\n",
      " [ 33  46  29 217 117  28  48  35  40  25  23  52  67]\n",
      " [  4  29   0  22 506   8  31  20   4  10  10  16  15]\n",
      " [ 89  32  41   2  82 323  18  27  27 157  36  11  56]\n",
      " [ 16  14  11  21  41   8 178  24  19   7  18  10  23]\n",
      " [ 91  18 117  29  27  64  43 863  28 165  84  41  26]\n",
      " [160  61 250  55  70  90  31  96 480 203  28 104 234]\n",
      " [ 70   6  91   6  13  16   6  53  27 376  35  19  20]\n",
      " [134  57 117  23  59 190  25 464  96 197 533  65  85]\n",
      " [ 41  19  23  25  27  17  16 110  28  28  21  93  29]\n",
      " [  0   4   2  11   9   2   9   1  13   3   1   3 276]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Paths to the features and labels files\n",
    "features_path = 'D://SEM-4//ML//CODES//Machine-Learning//features_4096.npy'\n",
    "labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy'\n",
    "\n",
    "# Load features and labels\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Reshape features from 4D (n_samples, height, width, channels) to 2D (n_samples, height*width*channels)\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Dictionary of classifiers\n",
    "classifiers = {\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict the responses for the test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # Store results\n",
    "    results[name] = (accuracy, precision, recall, f1, conf_matrix)\n",
    "\n",
    "# Print all results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name} Performance Metrics:\")\n",
    "    print(f\"Accuracy: {metrics[0]:.2f}\")\n",
    "    print(f\"Precision: {metrics[1]:.2f}\")\n",
    "    print(f\"Recall: {metrics[2]:.2f}\")\n",
    "    print(f\"F1 Score: {metrics[3]:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics[4])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA to explain 99% variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of principal components selected to explain at least 99% of the variance: 3300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Paths to the features and labels files\n",
    "features_path = 'D://SEM-4//ML//CODES//Machine-Learning//features_4096.npy'\n",
    "labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy'# Load features and labels\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Reshape features from 4D (n_samples, height, width, channels) to 2D (n_samples, height*width*channels)\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Applying PCA to capture 99% of the variance\n",
    "pca = PCA(0.99)\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "# Saving the reduced features to a new file\n",
    "reduced_features_path = 'D://SEM-4//ML//CODES//Machine-Learning//Reduced//reduced_features.npy'\n",
    "np.save(reduced_features_path, features_pca)\n",
    "\n",
    "# Optionally, save the labels if you need to keep them aligned with the reduced features for later use\n",
    "reduced_labels_path = 'D://SEM-4//ML//CODES//Machine-Learning//Reduced//reduced_labels.npy'\n",
    "np.save(reduced_labels_path, labels)\n",
    "\n",
    "# Number of components selected\n",
    "n_components = pca.n_components_\n",
    "print(f\"Number of principal components selected to explain at least 99% of the variance: {n_components}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Performance Metrics:\n",
      "Accuracy: 0.57\n",
      "Precision: 0.58\n",
      "Recall: 0.57\n",
      "F1 Score: 0.56\n",
      "Confusion Matrix:\n",
      "[[ 134    4   55    2    7   10    0   41   66   27   59    1    2]\n",
      " [   3  577   10   51   66   18   11   36   81    4   67    8    4]\n",
      " [   4   13  943   15    1   31    8  106  264   61  179    2    1]\n",
      " [   0   53   24  435   23   13   14   45   83    1   57    8    4]\n",
      " [   1   62    2   33  492    7    6   24   22    2   21    2    1]\n",
      " [  16   33   93    7    0  480    1   29   98   47   94    2    1]\n",
      " [   0   28   14   38   14    6  188   18   44    2   36    1    1]\n",
      " [   8    9  118   25    8   20    3  991  102   26  278    6    2]\n",
      " [   4   50  235   34   20   41    5   54 1290   23   80    6   20]\n",
      " [   8   10  162    3    1   29    0   33   95  279  118    0    0]\n",
      " [  15   40  150   30   11   48    9  253  202   71 1206    4    6]\n",
      " [   3   17   35   46   14   13    7  107  102    1   78   51    3]\n",
      " [   0   20    2   13    5    3    1    1   64    1    6    0  218]]\n",
      "\n",
      "\n",
      "XGBoost Performance Metrics:\n",
      "Accuracy: 0.54\n",
      "Precision: 0.56\n",
      "Recall: 0.54\n",
      "F1 Score: 0.52\n",
      "Confusion Matrix:\n",
      "[[ 102    6   56    2    4    8    0   42   77   23   88    0    0]\n",
      " [   3  521   16   41   58   11    8   43  110    5  111    3    6]\n",
      " [   2   15  912    6    3   12    1  128  280   40  228    1    0]\n",
      " [   0   42   34  359   32   10   12   59  120    2   81    4    5]\n",
      " [   1   65    7   35  470    4    1   26   28    1   35    0    2]\n",
      " [  13   27   88    2    5  450    0   34  119   37  123    1    2]\n",
      " [   0   35   15   26   15    3  125   30   80    0   56    0    5]\n",
      " [   3    8  124   19    9   17    0  963  119   12  316    4    2]\n",
      " [   2   43  237   28   15   21    1   62 1290   15  124    2   22]\n",
      " [   7    6  184    0    1   18    0   50  116  207  149    0    0]\n",
      " [  10   31  167   18    9   24    7  261  236   39 1237    3    3]\n",
      " [   0   14   40   32    7    6    4  116  124    8  107   17    2]\n",
      " [   0   14    2   15    5    0    2    5   89    1   14    1  186]]\n",
      "\n",
      "\n",
      "SVM Performance Metrics:\n",
      "Accuracy: 0.64\n",
      "Precision: 0.65\n",
      "Recall: 0.64\n",
      "F1 Score: 0.63\n",
      "Confusion Matrix:\n",
      "[[ 158    7   36    5    6   12    0   45   45   27   61    4    2]\n",
      " [   3  641   17   49   40    8   10   38   49    4   60    9    8]\n",
      " [  10   13 1052    6    3   13    5   94  209   61  161    1    0]\n",
      " [   1   37   24  498   20   10   14   47   57    1   38   10    3]\n",
      " [   2   56    4   26  517    2    4   21   17    0   21    5    0]\n",
      " [  16   22   74    7    1  537    1   18   80   67   75    2    1]\n",
      " [   0   21   11   29    8    3  246   18   30    1   16    5    2]\n",
      " [  11   12  103   23   10   13    5 1101   65   22  223    6    2]\n",
      " [   3   32  210   28   14   23    3   55 1395   19   57    8   15]\n",
      " [  13    5  134    3    2   17    0   34   72  353  104    1    0]\n",
      " [  18   28  129   31    5   28    7  242  162   71 1309   12    3]\n",
      " [   5   21   31   39    9    7    9  106   87    2   63   92    6]\n",
      " [   0   15    4   11    3    0    0    2   41    0    4    0  254]]\n",
      "\n",
      "\n",
      "Random Forest Performance Metrics:\n",
      "Accuracy: 0.33\n",
      "Precision: 0.46\n",
      "Recall: 0.33\n",
      "F1 Score: 0.30\n",
      "Confusion Matrix:\n",
      "[[  10    1   94    0    0    3    0   57  126    2  115    0    0]\n",
      " [   0  188   88   13   17    9    0   84  257    1  279    0    0]\n",
      " [   0    1  615    2    0    8    0  152  432    4  414    0    0]\n",
      " [   0   17  108   37    3    6    0   86  287    1  215    0    0]\n",
      " [   0   33   67   11  104    4    0   83  185    0  188    0    0]\n",
      " [   0    8  117    1    0  264    0   67  207    4  233    0    0]\n",
      " [   0   17   57    7    4    5   29   46  133    0   92    0    0]\n",
      " [   0    2  169    1    0   11    0  692  227    1  493    0    0]\n",
      " [   0   12  306    4    4    8    0  143 1085    1  299    0    0]\n",
      " [   0    2  182    1    0    7    0   79  205   23  239    0    0]\n",
      " [   0    8  201    4    0   15    0  264  363    5 1185    0    0]\n",
      " [   0    6   56    1    0    3    0  114  137    0  160    0    0]\n",
      " [   0    5   31    4    0    3    0   20  166    1   69    0   35]]\n",
      "\n",
      "\n",
      "AdaBoost Performance Metrics:\n",
      "Accuracy: 0.31\n",
      "Precision: 0.30\n",
      "Recall: 0.31\n",
      "F1 Score: 0.30\n",
      "Confusion Matrix:\n",
      "[[ 11  16 101   1  11  14   9  44 144  18  37   0   2]\n",
      " [  4 281  26  55 203  38  34  29 139   3  92   0  32]\n",
      " [  3  47 612  36  30  64  19 145 339  59 265   2   7]\n",
      " [  3  72  37 205  98  28  35  34 170   2  39   2  35]\n",
      " [  0 190   9  54 273   9  28  26  42   2  26   0  16]\n",
      " [  5  98 166  15  37 198   5  33 145  15 169   1  14]\n",
      " [  1  40  25  51  45   8  78  24  56   2  46   1  13]\n",
      " [  2  25 196  42  44  55  27 596 157  17 425   1   9]\n",
      " [  3 126 307  92  63  92  36  61 788  37 157   1  99]\n",
      " [  4  19 284  18   6  38   6  59 123  60 116   0   5]\n",
      " [  8  87 248  28  40 131  18 423 273  34 734   4  17]\n",
      " [  1  29  33  45  35  15   9  81 114   6 102   1   6]\n",
      " [  0  23   6  21   8   8  13   6  63   0  15   0 171]]\n",
      "\n",
      "\n",
      "Decision Tree Performance Metrics:\n",
      "Accuracy: 0.28\n",
      "Precision: 0.28\n",
      "Recall: 0.28\n",
      "F1 Score: 0.28\n",
      "Confusion Matrix:\n",
      "[[ 51  10  61  13   7  35  12  47  63  40  54  12   3]\n",
      " [ 10 286  48  77  95  56  35  63 109  19  87  28  23]\n",
      " [ 58  54 441  56  20 108  29 184 251 154 218  44  11]\n",
      " [ 21  68  53 156  43  46  40  64 105  24  70  41  29]\n",
      " [  3 116  25  61 263  17  24  34  59  17  17  28  11]\n",
      " [ 29  56 103  31  14 305  18  65  97  59  96  21   7]\n",
      " [  7  35  29  43  29  13  79  42  43   8  35  20   7]\n",
      " [ 59  38 170  63  35  68  41 487 149  76 325  69  16]\n",
      " [ 59  99 245 109  56 116  42 137 559 115 187  65  73]\n",
      " [ 42  13 129  22   6  62   9  90  98 135 104  17  11]\n",
      " [ 64  90 202  68  41 117  31 311 184 128 700  77  32]\n",
      " [ 17  35  44  46  16  22  15  75  66  18  83  29  11]\n",
      " [  4  23  21  29  17  13   7  12  55  10  25  18 100]]\n",
      "\n",
      "\n",
      "Naive Bayes Performance Metrics:\n",
      "Accuracy: 0.21\n",
      "Precision: 0.29\n",
      "Recall: 0.21\n",
      "F1 Score: 0.19\n",
      "Confusion Matrix:\n",
      "[[  61   10   18   15    3    5   78  145   36    6   24    4    3]\n",
      " [  10  120   49   24   23   20  239  303   54    3   59   22   10]\n",
      " [  14   49  217   38    4   11  252  738  197   22   49    8   29]\n",
      " [   9   20   45  124    8    4  216  205   41    5   42   29   12]\n",
      " [   3   31   20   10   93    2  184  247    6    3   57   12    7]\n",
      " [  17   30   25   12    9   90  102  478   77   19   15    3   24]\n",
      " [   5   13   25   20    9    2  185   63   34    0   13   20    1]\n",
      " [  20   45   83   45    5    7  172 1004  105   14   58   27   11]\n",
      " [  21   46  142   39    6   20  480  545  350   21   87   32   73]\n",
      " [  11   12   51   13    1    4   78  385   81   66   20    4   12]\n",
      " [  28   60   71   53   14   13  263 1073  192   16  212   21   29]\n",
      " [   7   10   16   19    4    1   66  253   42    0   30   27    2]\n",
      " [   2    1   28    4    3    9   65   67   33    5   16    6   95]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Paths to the features and labels files\n",
    "features_path = 'D://SEM-4//ML//CODES//Machine-Learning//Reduced//reduced_features.npy'\n",
    "labels_path = 'D://SEM-4//ML//CODES//Machine-Learning//Reduced//reduced_labels.npy'\n",
    "\n",
    "# Load features and labels\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Reshape features from 4D (n_samples, height, width, channels) to 2D (n_samples, height*width*channels)\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Dictionary of classifiers\n",
    "classifiers = {\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict the responses for the test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # Store results\n",
    "    results[name] = (accuracy, precision, recall, f1, conf_matrix)\n",
    "\n",
    "# Print all results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name} Performance Metrics:\")\n",
    "    print(f\"Accuracy: {metrics[0]:.2f}\")\n",
    "    print(f\"Precision: {metrics[1]:.2f}\")\n",
    "    print(f\"Recall: {metrics[2]:.2f}\")\n",
    "    print(f\"F1 Score: {metrics[3]:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics[4])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.42      0.44       408\n",
      "           1       0.57      0.62      0.59       936\n",
      "           2       0.44      0.56      0.49      1628\n",
      "           3       0.53      0.51      0.52       760\n",
      "           4       0.73      0.71      0.72       675\n",
      "           5       0.64      0.56      0.60       901\n",
      "           6       0.72      0.50      0.59       390\n",
      "           7       0.56      0.56      0.56      1596\n",
      "           8       0.48      0.57      0.53      1862\n",
      "           9       0.43      0.44      0.44       738\n",
      "          10       0.56      0.50      0.52      2045\n",
      "          11       0.38      0.12      0.19       477\n",
      "          12       0.63      0.77      0.69       334\n",
      "\n",
      "    accuracy                           0.54     12750\n",
      "   macro avg       0.55      0.52      0.53     12750\n",
      "weighted avg       0.54      0.54      0.53     12750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load features and labels\n",
    "features_path = 'D://SEM-4//ML//CODES//Machine-Learning//features_4096.npy'\n",
    "labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\labels_4096.npy'\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# For example, training a RandomForest Classifier to see the effect of SMOTE\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.29       408\n",
      "           1       0.40      0.44      0.42       936\n",
      "           2       0.28      0.34      0.31      1628\n",
      "           3       0.31      0.30      0.31       760\n",
      "           4       0.52      0.52      0.52       675\n",
      "           5       0.45      0.46      0.45       901\n",
      "           6       0.44      0.37      0.40       390\n",
      "           7       0.37      0.39      0.38      1596\n",
      "           8       0.34      0.34      0.34      1862\n",
      "           9       0.30      0.28      0.29       738\n",
      "          10       0.38      0.34      0.36      2045\n",
      "          11       0.14      0.06      0.08       477\n",
      "          12       0.59      0.61      0.60       334\n",
      "\n",
      "    accuracy                           0.36     12750\n",
      "   macro avg       0.37      0.37      0.37     12750\n",
      "weighted avg       0.36      0.36      0.36     12750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load features and labels\n",
    "features_path = 'D://SEM-4//ML//CODES\\Machine-Learning//Reduced 4096//reduced_features.npy'\n",
    "labels_path = 'D://SEM-4//ML//CODES//Machine-Learning//Reduced 4096//reduced_labels.npy'\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# For example, training a RandomForest Classifier to see the effect of SMOTE\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
