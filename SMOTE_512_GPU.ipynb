{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing cuML: No module named 'cuml'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\SEM-\\\\ML\\\\CODES\\\\Machine-Learning\\\\Lab04\\\\extracted_features.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m features_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSEM-\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mML\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCODES\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mMachine-Learning\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLab04\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mextracted_features.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     37\u001b[0m labels_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSEM-4\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mML\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCODES\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mMachine-Learning\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mLab04\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mlabels.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 39\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(labels_path)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Reshape features from 4D (n_samples, height, width, channels) to 2D (n_samples, height*width*channels)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\SEM-\\\\ML\\\\CODES\\\\Machine-Learning\\\\Lab04\\\\extracted_features.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "try:\n",
    "        from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "except ImportError as e:\n",
    "        print(f\"Error importing scikit-learn: {e}\")\n",
    "        exit()\n",
    "try:\n",
    "        import cuml\n",
    "        from cuml.svm import SVC as cumlSVC\n",
    "        from cuml.ensemble import RandomForestClassifier as cumlRF\n",
    "        from cuml.naive_bayes import MultinomialNB as cumlNB\n",
    "except ImportError as e:\n",
    "        print(f\"Error importing cuML: {e}\")\n",
    "        # Optionally continue without cuML if it's not crucial\n",
    "try:\n",
    "        from xgboost import XGBClassifier\n",
    "except ImportError as e:\n",
    "        print(f\"Error importing XGBoost: {e}\")\n",
    "        # Optionally continue without XGBoost if it's not crucial\n",
    "try:\n",
    "        from catboost import CatBoostClassifier\n",
    "except ImportError as e:\n",
    "        print(f\"Error importing CatBoost: {e}\")\n",
    "        # Optionally continue without CatBoost if it's not crucial\n",
    "\n",
    "try:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "except ImportError as e:\n",
    "        print(f\"Error importing imbalanced-learn: {e}\")\n",
    "        exit()\n",
    "\n",
    "# Load features and labels\n",
    "features_path = 'D:\\\\SEM-\\\\ML\\\\CODES\\\\Machine-Learning\\\\Lab04\\\\extracted_features.npy'\n",
    "labels_path = 'D:\\\\SEM-4\\\\ML\\\\CODES\\\\Machine-Learning\\\\Lab04\\\\labels.npy'\n",
    "\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Reshape features from 4D (n_samples, height, width, channels) to 2D (n_samples, height*width*channels)\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define parameter grids\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "param_grid_adaboost = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 10]\n",
    "}\n",
    "\n",
    "param_grid_nb = {}  # cuML Naive Bayes doesn't have many parameters to tune\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [6, 10],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'tree_method': ['gpu_hist']\n",
    "}\n",
    "\n",
    "param_grid_catboost = {\n",
    "    'iterations': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'depth': [4, 6, 10],\n",
    "    'task_type': ['GPU']\n",
    "}\n",
    "\n",
    "# Setup cross-validation strategy\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Dictionary of classifiers\n",
    "classifiers = {\n",
    "    \"CatBoost\": GridSearchCV(CatBoostClassifier(verbose=0, task_type='GPU'), param_grid_catboost, cv=cv_strategy, scoring='accuracy') if 'CatBoostClassifier' in globals() else None,\n",
    "    \"XGBoost\": GridSearchCV(XGBClassifier(tree_method='gpu_hist'), param_grid_xgb, cv=cv_strategy, scoring='accuracy') if 'XGBClassifier' in globals() else None,\n",
    "    \"SVM\": GridSearchCV(cumlSVC(), param_grid_svm, cv=cv_strategy, scoring='accuracy') if 'cumlSVC' in globals() else None,\n",
    "    \"Random Forest\": GridSearchCV(cumlRF(), param_grid_rf, cv=cv_strategy, scoring='accuracy') if 'cumlRF' in globals() else None,\n",
    "    \"AdaBoost\": GridSearchCV(AdaBoostClassifier(), param_grid_adaboost, cv=cv_strategy, scoring='accuracy'),\n",
    "    \"Decision Tree\": GridSearchCV(DecisionTreeClassifier(), param_grid_dt, cv=cv_strategy, scoring='accuracy'),\n",
    "    \"Naive Bayes\": cumlNB() if 'cumlNB' in globals() else GaussianNB()\n",
    "}\n",
    "\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    if clf is None:\n",
    "        print(f\"{name} is not available due to an import error.\")\n",
    "        continue\n",
    "    # Start timer for training\n",
    "    start_time_train = time.time()\n",
    "    \n",
    "    # Train the classifier with SMOTE-applied training data\n",
    "    clf.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # End timer for training\n",
    "    end_time_train = time.time()\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = end_time_train - start_time_train\n",
    "    \n",
    "    # Start timer for prediction\n",
    "    start_time_pred = time.time()\n",
    "    \n",
    "    # Predict the responses for the test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # End timer for prediction\n",
    "    end_time_pred = time.time()\n",
    "    \n",
    "    # Calculate prediction time\n",
    "    prediction_time = end_time_pred - start_time_pred\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Print best parameters (if clf uses GridSearchCV)\n",
    "    best_params = clf.best_params_ if isinstance(clf, GridSearchCV) else \"N/A\"\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = (accuracy, precision, recall, f1, conf_matrix, training_time, prediction_time, best_params)\n",
    "\n",
    "# Print all results\n",
    "for name, metrics in results.items():\n",
    "    if metrics:\n",
    "        print(f\"{name} Performance Metrics:\")\n",
    "        print(f\"Accuracy: {metrics[0]:.2f}\")\n",
    "        print(f\"Precision: {metrics[1]:.2f}\")\n",
    "        print(f\"Recall: {metrics[2]:.2f}\")\n",
    "        print(f\"F1 Score: {metrics[3]:.2f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(metrics[4])\n",
    "        print(f\"Training Time: {metrics[5]:.4f} seconds\")\n",
    "        print(f\"Prediction Time: {metrics[6]:.4f} seconds\")\n",
    "        print(f\"Best Parameters: {metrics[7]}\")\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
