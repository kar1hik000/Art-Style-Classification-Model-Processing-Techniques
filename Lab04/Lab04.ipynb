{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# Load VGG16 pre-trained on ImageNet without the top classification layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Freeze the layers of the base_model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add GlobalAveragePooling2D layer to the model\n",
    "gap_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "model = Model(inputs=base_model.input, outputs=gap_layer)\n",
    "\n",
    "# Prepare your data generators\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "generator = datagen.flow_from_directory(\n",
    "    'E:\\\\College\\\\SEMESTER 4\\\\MACHINE LEARNING\\\\Archive',  # Update this path\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode=None,  # No labels needed\n",
    "    shuffle=False)\n",
    "\n",
    "# Use model to predict and extract features\n",
    "features = model.predict(generator, steps=np.ceil(generator.samples/generator.batch_size))\n",
    "\n",
    "# Get labels associated with each feature\n",
    "labels = generator.classes\n",
    "\n",
    "# Save the extracted features and labels\n",
    "np.save('extracted_features.npy', features)\n",
    "np.save('labels.npy', labels)\n",
    "\n",
    "# Example to load the extracted features and labels\n",
    "loaded_features = np.load('extracted_features.npy')\n",
    "loaded_labels = np.load('labels.npy')\n",
    "\n",
    "# You can now use `loaded_features` and `loaded_labels` for further analysis or machine learning tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the extracted features from the .npy file\n",
    "loaded_features = np.load('extracted_features.npy')\n",
    "\n",
    "# Now, `loaded_features` is a NumPy array containing the data from the file\n",
    "print(\"Shape of loaded features:\", loaded_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the extracted features and labels\n",
    "loaded_features = np.load('extracted_features.npy')\n",
    "loaded_labels = np.load('labels.npy')\n",
    "\n",
    "# Perform PCA on the loaded features to reduce to 5 features\n",
    "pca = PCA(n_components=5)\n",
    "reduced_features = pca.fit_transform(loaded_features)\n",
    "\n",
    "# Manually defined mapping from class indices to class names\n",
    "class_indices_to_names = {\n",
    "    0: 'Academic Art',\n",
    "    1: 'Art Nouveau',\n",
    "    2: 'Baroque',\n",
    "    3: 'Expressionism',\n",
    "    4: 'Japanese Art',\n",
    "    5: 'Neoclassism',\n",
    "    6: 'Primitivism',\n",
    "    7: 'Realism',\n",
    "    8: 'Renaissance',\n",
    "    9: 'Rococo',\n",
    "    10: 'Romanticism',\n",
    "    11: 'Symbolism',\n",
    "    12: 'Western Medieval'\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to hold reduced features by class names\n",
    "reduced_features_by_class = {name: [] for name in class_indices_to_names.values()}\n",
    "\n",
    "# Populate the dictionary with reduced features\n",
    "for feature, label in zip(reduced_features, loaded_labels):\n",
    "    class_name = class_indices_to_names[label]\n",
    "    reduced_features_by_class[class_name].append(feature)\n",
    "\n",
    "# Print the reduced feature vectors organized by class names\n",
    "for class_name, features in reduced_features_by_class.items():\n",
    "    print(f\"Class: {class_name}, Number of Feature Vectors: {len(features)}\")\n",
    "    for feature_vector in features:\n",
    "        print(feature_vector)\n",
    "    print(\"\\n\")  # Adds a newline for readability between classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Initialize dictionaries to hold centroids and spreads for each class\n",
    "class_centroids = {}\n",
    "class_spreads = {}\n",
    "\n",
    "for class_name, features in reduced_features_by_class.items():\n",
    "    # Convert list of features to numpy array for easier calculations\n",
    "    features_np = np.array(features)\n",
    "    # Calculate the centroid (mean vector) for each class\n",
    "    class_centroids[class_name] = np.mean(features_np, axis=0)\n",
    "    # Calculate the spread (standard deviation) for each class\n",
    "    class_spreads[class_name] = np.std(features_np, axis=0)\n",
    "\n",
    "# Print the centroids and spreads for each class\n",
    "for class_name in class_centroids:\n",
    "    print(f\"Class: {class_name}\")\n",
    "    print(f\"  Centroid (Mean): {class_centroids[class_name]}\")\n",
    "    print(f\"  Spread (Standard Deviation): {class_spreads[class_name]}\\n\")\n",
    "# Calculate the distance between centroids of two classes\n",
    "distance = norm(class_centroids['Academic Art'] - class_centroids['Art Nouveau'])\n",
    "print(f\"Distance between centroids of 'Academic Art' and 'Art Nouveau': {distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Further reduce the PCA-reduced features to 2 dimensions for visualization\n",
    "pca_2d = PCA(n_components=2)\n",
    "reduced_features_2d = pca_2d.fit_transform(reduced_features)\n",
    "\n",
    "# Calculate 2D centroids for visualization\n",
    "centroids_2d = {}\n",
    "for class_name, features in reduced_features_by_class.items():\n",
    "    features_2d = pca_2d.transform(np.array(features))  # Transform to 2D\n",
    "    centroids_2d[class_name] = np.mean(features_2d, axis=0)\n",
    "\n",
    "# Plot the 2D centroids of 'Academic Art' and 'Art Nouveau'\n",
    "plt.figure(figsize=(8, 6))\n",
    "for class_name, centroid in centroids_2d.items():\n",
    "    plt.scatter(centroid[0], centroid[1], label=class_name)\n",
    "\n",
    "# Draw a line between the centroids of 'Academic Art' and 'Art Nouveau'\n",
    "plt.plot([centroids_2d['Academic Art'][0], centroids_2d['Art Nouveau'][0]],\n",
    "         [centroids_2d['Academic Art'][1], centroids_2d['Art Nouveau'][1]],\n",
    "         'k--', linewidth=1)\n",
    "\n",
    "plt.xlabel('PCA Feature 1')\n",
    "plt.ylabel('PCA Feature 2')\n",
    "plt.title('Centroids of Classes in 2D PCA-Reduced Feature Space')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming reduced_features contains the PCA-reduced features of your dataset\n",
    "# Select the first feature for all samples\n",
    "selected_feature = reduced_features[:, 0]\n",
    "\n",
    "# Calculate the histogram data\n",
    "hist_data, bin_edges = np.histogram(selected_feature, bins='auto')\n",
    "\n",
    "# Calculate mean and variance\n",
    "mean = np.mean(selected_feature)\n",
    "variance = np.var(selected_feature)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(selected_feature, bins='auto', alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of the Selected Feature')\n",
    "plt.xlabel('Feature Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Annotate mean and variance on the plot\n",
    "plt.axvline(mean, color='r', linestyle='dashed', linewidth=1)\n",
    "plt.text(mean, plt.ylim()[1]*0.9, f'Mean: {mean:.2f}', color = 'red')\n",
    "plt.axvline(mean - np.sqrt(variance), color='g', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(mean + np.sqrt(variance), color='g', linestyle='dashed', linewidth=1)\n",
    "plt.text(mean + np.sqrt(variance), plt.ylim()[1]*0.9, f'Std Dev: {np.sqrt(variance):.2f}', color = 'green')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print the mean and variance\n",
    "print(f\"Mean of the selected feature: {mean}\")\n",
    "print(f\"Variance of the selected feature: {variance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import minkowski\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming reduced_features contains the PCA-reduced features of your dataset\n",
    "# Let's take two feature vectors, for example, the first and second feature vectors in the dataset\n",
    "feature_vector_1 = reduced_features[0]\n",
    "feature_vector_2 = reduced_features[1]\n",
    "\n",
    "# Calculate the Minkowski distance for r values from 1 to 10\n",
    "r_values = range(1, 11)\n",
    "distances = [minkowski(feature_vector_1, feature_vector_2, r) for r in r_values]\n",
    "\n",
    "# Plot the Minkowski distance as a function of r\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(r_values, distances, marker='o', linestyle='-', color='b')\n",
    "plt.title('Minkowski Distance Between Two Feature Vectors')\n",
    "plt.xlabel('r value')\n",
    "plt.ylabel('Minkowski Distance')\n",
    "plt.xticks(r_values)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the indices for the selected classes\n",
    "selected_class_indices = [0, 1]  # Example: 0 for 'Academic Art', 1 for 'Art Nouveau'\n",
    "\n",
    "# Filter features and labels for the selected classes\n",
    "selected_features = loaded_features[np.isin(loaded_labels, selected_class_indices)]\n",
    "selected_labels = loaded_labels[np.isin(loaded_labels, selected_class_indices)]\n",
    "\n",
    "# Convert labels to a binary format for simplicity (0 and 1)\n",
    "selected_labels = np.array([0 if label == selected_class_indices[0] else 1 for label in selected_labels])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, selected_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the kNN classifier with k=3\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier using the training set\n",
    "neigh.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = neigh.score(X_test, y_test)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming class_indices_to_names maps numerical labels to class names\n",
    "predicted_class_name = class_indices_to_names[predicted_class[0]]\n",
    "print(predicted_class_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store accuracies for different values of k\n",
    "k_values = range(1, 12)\n",
    "accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    # Initialize the kNN classifier with the current value of k\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Train the classifier on the training set\n",
    "    neigh.fit(X_train, y_train)\n",
    "    # Predict the class labels for the test set\n",
    "    y_pred = neigh.predict(X_test)\n",
    "    # Calculate the accuracy of the predictions\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # Store the accuracy in the list\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Plot the accuracy for different values of k\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('k-NN Classifier Accuracy')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Assuming neigh is your trained kNN classifier with the chosen k value\n",
    "# Predict the class labels for the test set\n",
    "y_pred_test = neigh.predict(X_test)\n",
    "y_pred_train = neigh.predict(X_train)\n",
    "\n",
    "# Evaluate confusion matrix for test data\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Confusion Matrix (Test Data):\")\n",
    "print(conf_matrix_test)\n",
    "\n",
    "# Evaluate confusion matrix for training data\n",
    "conf_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "print(\"\\nConfusion Matrix (Training Data):\")\n",
    "print(conf_matrix_train)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for both training and test data\n",
    "print(\"\\nClassification Report (Test Data):\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "print(\"Classification Report (Training Data):\")\n",
    "print(classification_report(y_train, y_pred_train))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
