{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\garik\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Performance Metrics:\n",
      "Accuracy: 0.52\n",
      "Precision: 0.53\n",
      "Recall: 0.52\n",
      "F1 Score: 0.52\n",
      "Confusion Matrix:\n",
      "[[ 108    5   54   10    2    6    3   65   66   26   56    6    1]\n",
      " [   7  513   18   49   56   21   13   60  109    8   61    4   17]\n",
      " [   9   18  936   16    7   31    5  148  196   73  180    6    3]\n",
      " [   4   51   30  326   34   18   19   56  134    7   60   11   10]\n",
      " [   1   67   10   30  418    6   14   36   62    0   26    1    4]\n",
      " [  15   30   94    8    5  474    2   39   76   56  100    0    2]\n",
      " [   1   26    8   46   14    5  149   43   60    2   30    3    3]\n",
      " [   9   20  165   25    7   19   15  901  109   21  286   12    7]\n",
      " [  16   61  226   56   21   32   12   93 1208   23   77    7   30]\n",
      " [  13    8  179   10    1   23    2   52   51  293  103    0    3]\n",
      " [  19   34  162   21   16   58    8  308  200   76 1123   11    9]\n",
      " [   7   26   32   47    8   17    2  112   79    6   95   43    3]\n",
      " [   0   13    4   24   11    6    6   10   62    2   11    1  184]]\n",
      "\n",
      "\n",
      "XGBoost Performance Metrics:\n",
      "Accuracy: 0.51\n",
      "Precision: 0.52\n",
      "Recall: 0.51\n",
      "F1 Score: 0.50\n",
      "Confusion Matrix:\n",
      "[[  94    6   64    8    3    9    1   54   66   32   68    3    0]\n",
      " [   1  513   24   37   51   27   12   41  127    3   87    7    6]\n",
      " [   6   12  918   14    5   23    0  146  221   73  204    4    2]\n",
      " [   6   61   36  312   26   16   17   56  152    6   56   11    5]\n",
      " [   0   76   14   29  388    7    8   41   74    0   34    0    4]\n",
      " [  13   30  100    4    6  472    2   50   78   45   99    2    0]\n",
      " [   0   25   18   36   10    1  134   41   91    3   26    2    3]\n",
      " [   4   17  153   19    6   22    7  863  131   25  335    9    5]\n",
      " [   9   57  262   66   15   25   10   83 1168   18  115   11   23]\n",
      " [   9    6  197    6    2   27    4   44   71  238  132    1    1]\n",
      " [  10   36  180   18   12   48    2  284  219   62 1160    6    8]\n",
      " [   4   26   47   36    5   12    4  100   93   11  108   29    2]\n",
      " [   0   21    7   24    7    6    2   10   73    1   17    3  163]]\n",
      "\n",
      "\n",
      "SVM Performance Metrics:\n",
      "Accuracy: 0.41\n",
      "Precision: 0.44\n",
      "Recall: 0.41\n",
      "F1 Score: 0.38\n",
      "Confusion Matrix:\n",
      "[[   5    8  108    1    3    1    0   42  100   20  120    0    0]\n",
      " [   0  411   17   27   81   39   11   55  161    3  131    0    0]\n",
      " [   0   27  831    4    6   36    2  120  238   24  340    0    0]\n",
      " [   0   73   49  142   38   12    8   45  303    3   87    0    0]\n",
      " [   0  105   13   27  325   12    4   42  101    0   46    0    0]\n",
      " [   1   61  143    4    9  344    1   55   92   31  160    0    0]\n",
      " [   0   28   29   38   12    4   82   44  106    1   46    0    0]\n",
      " [   1   20  215    4    6   22    6  693  130   11  486    0    2]\n",
      " [   0   81  303   25   28   27    3  120 1101   16  157    0    1]\n",
      " [   0   12  281    1    0   10    3   55   81  150  145    0    0]\n",
      " [   0   37  216    8    6   51    1  282  269   45 1130    0    0]\n",
      " [   0   20   39   13    7   10    2   93  124    2  167    0    0]\n",
      " [   0   33    9   17   11    5    8   10  183    0   41    0   17]]\n",
      "\n",
      "\n",
      "Random Forest Performance Metrics:\n",
      "Accuracy: 0.45\n",
      "Precision: 0.49\n",
      "Recall: 0.45\n",
      "F1 Score: 0.43\n",
      "Confusion Matrix:\n",
      "[[  41    4   97    3    3    5    1   68  114   25   47    0    0]\n",
      " [   0  482   24   21   49   32    4   65  155    4   99    0    1]\n",
      " [   3   23  859    5    8   29    0  175  238   43  245    0    0]\n",
      " [   0   80   49  181   27   13    3   63  277    2   62    0    3]\n",
      " [   0   89   18   16  318   10    3   59  125    2   35    0    0]\n",
      " [   3   44  107    5    7  450    1   46  103   44   90    1    0]\n",
      " [   1   46   25   25   15    7   56   42  130    2   40    0    1]\n",
      " [   5   26  202   12    7   17    0  828  138   30  330    0    1]\n",
      " [   1   74  283   36   14   31    2  133 1154   25  108    0    1]\n",
      " [   2   10  230    3    3   14    2   75   88  192  117    0    2]\n",
      " [   3   34  214   13   14   49    1  319  289   49 1060    0    0]\n",
      " [   0   23   45   30    5   16    0  127  114    5  111    1    0]\n",
      " [   0   41    5   21   10   10    1   15  147    1   31    0   52]]\n",
      "\n",
      "\n",
      "AdaBoost Performance Metrics:\n",
      "Accuracy: 0.28\n",
      "Precision: 0.27\n",
      "Recall: 0.28\n",
      "F1 Score: 0.27\n",
      "Confusion Matrix:\n",
      "[[ 47  10  83   7   5  15   6  66  74  46  46   0   3]\n",
      " [ 11 222  25  28 142 118  26  50 146   8 110   0  50]\n",
      " [ 25  37 541   8  21  45  16 302 262  75 278   0  18]\n",
      " [  6  65  48  64  45  41  63  41 262   5  81   0  39]\n",
      " [  1 141  28  29 177  43  31  31 120   1  43   0  30]\n",
      " [ 27  66 111   6  38 241  22  78  65  48 171   0  28]\n",
      " [  1  39  22  37  29  12  55  33  76   4  50   0  32]\n",
      " [ 21  48 217  11  23  44  22 539 149  41 468   0  13]\n",
      " [ 23  97 218  61  62  51  37 116 761  38 206   0 192]\n",
      " [ 29  10 192   2   3  30   4 138  97 124 103   0   6]\n",
      " [ 41  70 200  17  31 127  22 503 260  66 675   0  33]\n",
      " [  4  23  43   8  12  17  15  78 119   9 137   0  12]\n",
      " [  1  24   4  14   6  12  13  12  77   2  32   0 137]]\n",
      "\n",
      "\n",
      "Decision Tree Performance Metrics:\n",
      "Accuracy: 0.27\n",
      "Precision: 0.27\n",
      "Recall: 0.27\n",
      "F1 Score: 0.27\n",
      "Confusion Matrix:\n",
      "[[ 54  16  54  16   5  23   7  49  55  41  65  19   4]\n",
      " [ 24 267  48  55  99  72  32  60 102  23  81  36  37]\n",
      " [ 46  40 421  47  31 103  29 219 221 159 245  45  22]\n",
      " [ 21  70  56 144  44  36  36  47 124  31  81  41  29]\n",
      " [  6  84  31  47 193  32  32  54  89  18  55  11  23]\n",
      " [ 19  62  72  33  37 304  13  78  97  58 102  16  10]\n",
      " [  4  28  37  46  18  15  77  34  47  12  36  18  18]\n",
      " [ 44  67 197  52  46  67  33 464 143  93 305  69  16]\n",
      " [ 52 100 230 132  68  85  67 124 576  99 177  83  69]\n",
      " [ 45  14 116  25   8  60  12  84  67 158 114  22  13]\n",
      " [ 43  76 231  72  52 126  31 332 201 109 661  78  33]\n",
      " [ 11  20  52  30  21  30  20  86  66  20  73  31  17]\n",
      " [  6  42  16  29  16  16  22  15  63   6  28  10  65]]\n",
      "\n",
      "\n",
      "Naive Bayes Performance Metrics:\n",
      "Accuracy: 0.27\n",
      "Precision: 0.37\n",
      "Recall: 0.27\n",
      "F1 Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[175   4  32   6   4   9   5  72  15  37   3  41   5]\n",
      " [ 37 236  19  40  97 154  41 100   7   2  16 149  38]\n",
      " [167  13 469  19   3  51  23 571  26 102  22 150  12]\n",
      " [ 70  23  41  96  31  47  53  77  23  21   4 230  44]\n",
      " [ 27  43  13  14 231  51  44  89  16   4   5 114  24]\n",
      " [ 97  39  39  13   7 297  16 147   6  88  39  74  39]\n",
      " [ 20  18  17  17  24  16 114  53  13   7   7  66  18]\n",
      " [122   7  74  17  14  50  26 972  13  76  31 170  24]\n",
      " [224  62 230  66  26  70  53 248 167  93  30 386 207]\n",
      " [103   5  94   6   2  23  10 201   9 213  11  52   9]\n",
      " [162  22  97  30  19 132  19 938  23 110 148 306  39]\n",
      " [ 38  13  25  16   4  26  11 173   5  23   6 133   4]\n",
      " [  6   9   5  14  15  23  17  11  12   2   1  70 149]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Paths to the features and labels files\n",
    "features_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Lab04\\extracted_features.npy'\n",
    "labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Lab04\\labels.npy'\n",
    "\n",
    "# Load features and labels\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Reshape features from 4D (n_samples, height, width, channels) to 2D (n_samples, height*width*channels)\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Dictionary of classifiers\n",
    "classifiers = {\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict the responses for the test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # Store results\n",
    "    results[name] = (accuracy, precision, recall, f1, conf_matrix)\n",
    "\n",
    "# Print all results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name} Performance Metrics:\")\n",
    "    print(f\"Accuracy: {metrics[0]:.2f}\")\n",
    "    print(f\"Precision: {metrics[1]:.2f}\")\n",
    "    print(f\"Recall: {metrics[2]:.2f}\")\n",
    "    print(f\"F1 Score: {metrics[3]:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics[4])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of principal components selected to explain at least 99% of the variance: 270\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Paths to the features and labels files\n",
    "features_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Lab04\\extracted_features.npy'\n",
    "labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Lab04\\labels.npy'# Load features and labels\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Reshape features from 4D (n_samples, height, width, channels) to 2D (n_samples, height*width*channels)\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Applying PCA to capture 99% of the variance\n",
    "pca = PCA(0.99)\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "# Saving the reduced features to a new file\n",
    "reduced_features_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Reduced Features\\Features_reduced.npy'\n",
    "np.save(reduced_features_path, features_pca)\n",
    "\n",
    "# Optionally, save the labels if you need to keep them aligned with the reduced features for later use\n",
    "reduced_labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Reduced Features\\Labels_reduced.npy'\n",
    "np.save(reduced_labels_path, labels)\n",
    "\n",
    "# Number of components selected\n",
    "n_components = pca.n_components_\n",
    "print(f\"Number of principal components selected to explain at least 99% of the variance: {n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Performance Metrics:\n",
      "Accuracy: 0.50\n",
      "Precision: 0.51\n",
      "Recall: 0.50\n",
      "F1 Score: 0.50\n",
      "Confusion Matrix:\n",
      "[[  99    6   55    9    2    6    5   68   68   31   55    3    1]\n",
      " [   2  504   20   43   70   33   15   54  108    4   76    0    7]\n",
      " [  10   18  880   12    9   32    6  149  224   63  218    4    3]\n",
      " [   2   49   30  312   34   22   14   56  166    4   52    9   10]\n",
      " [   1   78   12   34  393   10    8   42   71    0   21    1    4]\n",
      " [  16   46   94    7    2  477    2   47   75   48   84    2    1]\n",
      " [   3   35   15   44   12    5  137   36   62    3   35    1    2]\n",
      " [  12   17  138   30    3   39    6  903  123   24  293    5    3]\n",
      " [  11   65  235   70   24   22    9   92 1166   24   99   10   35]\n",
      " [  19   10  165    4    0   25    5   48   74  271  115    2    0]\n",
      " [  16   36  157   33   13   58    9  310  222   60 1119    9    3]\n",
      " [   4   22   34   45    9   16    5  116   86    7  107   23    3]\n",
      " [   0   19    7   25    7    8    8   14   74    2   16    3  151]]\n",
      "\n",
      "\n",
      "XGBoost Performance Metrics:\n",
      "Accuracy: 0.48\n",
      "Precision: 0.49\n",
      "Recall: 0.48\n",
      "F1 Score: 0.46\n",
      "Confusion Matrix:\n",
      "[[  80    7   57    7    1    7    0   60   87   25   75    2    0]\n",
      " [   0  494   24   25   48   22    8   70  137    4   94    6    4]\n",
      " [   6   19  866   14    8   29    2  162  227   58  229    4    4]\n",
      " [   2   47   30  268   26   17   14   70  198    4   69   11    4]\n",
      " [   1   87   13   31  334   11    7   44   96    2   48    1    0]\n",
      " [   8   42   94    6    5  443    2   50   85   38  126    2    0]\n",
      " [   1   34   18   37   13    4  117   37   82    3   41    1    2]\n",
      " [   3   23  146   20    1   22    2  855  132   26  357    6    3]\n",
      " [   7   63  241   55   17   22    8  101 1164   19  143    5   17]\n",
      " [   6    3  180    5    1   33    1   68   87  196  156    1    1]\n",
      " [  12   25  172   19   11   52    4  310  249   58 1124    5    4]\n",
      " [   4   19   39   24   11   10    1  122  102    7  124   13    1]\n",
      " [   0   18   13   25   11    6    6   22  101    1   21    2  108]]\n",
      "\n",
      "\n",
      "SVM Performance Metrics:\n",
      "Accuracy: 0.55\n",
      "Precision: 0.56\n",
      "Recall: 0.55\n",
      "F1 Score: 0.54\n",
      "Confusion Matrix:\n",
      "[[ 120    9   64    6    2    3    1   53   69   28   52    0    1]\n",
      " [   5  574   17   42   47   18   14   55   97    3   54    0   10]\n",
      " [   9   20  986    9    7   14    5  137  195   56  184    2    4]\n",
      " [   4   50   22  379   18    9   13   58  133    7   49    7   11]\n",
      " [   1   67   10   32  434    5    9   36   56    0   22    0    3]\n",
      " [  13   33  102    4    4  488    3   41   63   59   91    0    0]\n",
      " [   0   27   13   32   13    0  179   35   57    2   25    1    6]\n",
      " [  10   23  158   22    6   17   10  937  120   23  263    2    5]\n",
      " [  11   57  247   54   17   16   13   90 1254   18   64    2   19]\n",
      " [  11    6  185    7    0   18    3   47   69  286  105    0    1]\n",
      " [  17   37  181   27   10   36    9  297  196   63 1162    4    6]\n",
      " [   4   26   40   43    5   12    5  113   96    5  110   17    1]\n",
      " [   0   20    5   30    4    0    2   14   58    3    9    1  188]]\n",
      "\n",
      "\n",
      "Random Forest Performance Metrics:\n",
      "Accuracy: 0.41\n",
      "Precision: 0.50\n",
      "Recall: 0.41\n",
      "F1 Score: 0.38\n",
      "Confusion Matrix:\n",
      "[[  24    8   85    3    0    5    0   61  124   14   84    0    0]\n",
      " [   0  416   34   11   39   26    1   67  195    1  146    0    0]\n",
      " [   0   19  817    6    2   24    0  148  283   22  307    0    0]\n",
      " [   1   57   63  117   17   15    2   78  311    5   94    0    0]\n",
      " [   0   91   28   18  221    8    1   47  188    1   72    0    0]\n",
      " [   0   38  120    3    5  402    0   54  124   26  129    0    0]\n",
      " [   0   33   28   19   12    8   46   47  137    1   59    0    0]\n",
      " [   0   15  209    8    4   17    0  726  190   12  415    0    0]\n",
      " [   3   56  274   23    8   24    0  127 1168   11  167    0    1]\n",
      " [   1    7  220    0    0   15    0   90  136  113  156    0    0]\n",
      " [   0   26  185    6    4   33    0  316  319   23 1133    0    0]\n",
      " [   0   19   58   12    0   16    0  105  130    1  134    2    0]\n",
      " [   0   21   14   12    5   10    1   14  205    1   32    0   19]]\n",
      "\n",
      "\n",
      "AdaBoost Performance Metrics:\n",
      "Accuracy: 0.29\n",
      "Precision: 0.28\n",
      "Recall: 0.29\n",
      "F1 Score: 0.27\n",
      "Confusion Matrix:\n",
      "[[ 59  12  91   5   4  24   6  61  73  20  51   0   2]\n",
      " [  8 280  25  25 139  99  28  58 126   3  96   1  48]\n",
      " [ 26  32 562  15  23  96   6 245 294  64 246   2  17]\n",
      " [  9  72  59  81  59  29  25  63 239   9  62   5  48]\n",
      " [  3 128  30  20 215  32  23  47 113   0  38   3  23]\n",
      " [ 26 127 104  14  23 254   5  76  87  31 136   0  18]\n",
      " [  3  48  21  27  37  25  50  42  67   5  36   1  28]\n",
      " [ 11  35 227  11  30  64  20 615 153  42 366   6  16]\n",
      " [ 49  71 252  71  37  90  31 146 722  32 181   6 174]\n",
      " [ 24  12 214   5   1  57   7 148  67  89 104   1   9]\n",
      " [ 34  86 236  26  39 136  13 547 250  41 607   5  25]\n",
      " [  7  27  52  20  10  17   9 123  87   6 102   5  12]\n",
      " [  0  21   3  12  28  10  15  13  73   2  30   2 125]]\n",
      "\n",
      "\n",
      "Decision Tree Performance Metrics:\n",
      "Accuracy: 0.25\n",
      "Precision: 0.25\n",
      "Recall: 0.25\n",
      "F1 Score: 0.25\n",
      "Confusion Matrix:\n",
      "[[ 46  26  63  23  18  21   8  48  57  25  52  15   6]\n",
      " [ 16 222  62  70  94  84  36  72 112  28  82  27  31]\n",
      " [ 53  46 454  58  32  90  27 218 198 111 252  61  28]\n",
      " [ 25  58  57 116  63  39  32  54 136  34  85  26  35]\n",
      " [ 19  79  45  60 169  41  32  50  54  14  68  18  26]\n",
      " [ 19  62  81  30  33 284  20  67 102  49 100  31  23]\n",
      " [ 15  30  34  45  19  18  66  37  51  11  36   9  19]\n",
      " [ 64  51 198  68  57  71  41 424 147 104 298  60  13]\n",
      " [ 69 103 201 134  75  99  53 182 507  94 194  75  76]\n",
      " [ 36  21 116  39   9  61   8  85  82 120 115  34  12]\n",
      " [ 52  82 212  90  65 115  37 290 209 116 675  70  32]\n",
      " [ 13  16  71  40  19  31  13  68  68  24  79  29   6]\n",
      " [  8  28  15  35  21  20  15  28  57   9  30   7  61]]\n",
      "\n",
      "\n",
      "Naive Bayes Performance Metrics:\n",
      "Accuracy: 0.31\n",
      "Precision: 0.32\n",
      "Recall: 0.31\n",
      "F1 Score: 0.30\n",
      "Confusion Matrix:\n",
      "[[112  24  34  15   0   5  14  87  36  23  39   7  12]\n",
      " [ 11 295  27  28  54  61  34 121  65   3 144  40  53]\n",
      " [ 50  46 418  33   6  16  28 524 205  55 203  22  22]\n",
      " [  8  63  32 179  17  23  58 104  82   9  87  44  54]\n",
      " [  4  89  38  18 190  16  47  98  32   2  83  27  31]\n",
      " [ 34 119  53  23   4 132  16 211  47  44 179   3  36]\n",
      " [  5  24  20  23   6  15 136  55  36   6  23  19  22]\n",
      " [ 41  46  74  42  21  23  36 943 112  31 164  42  21]\n",
      " [ 51 121 208  73  17  33  70 297 440  44 214  70 224]\n",
      " [ 35  33  83  17   3  16   7 199  59 149 121   6  10]\n",
      " [ 57  68  83  46   7  56  33 671 157  70 715  45  37]\n",
      " [ 10  25  14  26   4   7  15 182  50   9  86  37  12]\n",
      " [  3  12  12  12   6   9  12  36  45   2  26  15 144]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Paths to the features and labels files\n",
    "features_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Reduced Features\\Features_reduced.npy'\n",
    "labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Reduced Features\\Labels_reduced.npy'\n",
    "\n",
    "# Load features and labels\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Reshape features from 4D (n_samples, height, width, channels) to 2D (n_samples, height*width*channels)\n",
    "features = features.reshape(features.shape[0], -1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Dictionary of classifiers\n",
    "classifiers = {\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Results dictionary\n",
    "results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict the responses for the test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    # Store results\n",
    "    results[name] = (accuracy, precision, recall, f1, conf_matrix)\n",
    "\n",
    "# Print all results\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name} Performance Metrics:\")\n",
    "    print(f\"Accuracy: {metrics[0]:.2f}\")\n",
    "    print(f\"Precision: {metrics[1]:.2f}\")\n",
    "    print(f\"Recall: {metrics[2]:.2f}\")\n",
    "    print(f\"F1 Score: {metrics[3]:.2f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics[4])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.39      0.31       408\n",
      "           1       0.50      0.55      0.52       936\n",
      "           2       0.43      0.49      0.46      1628\n",
      "           3       0.34      0.39      0.36       760\n",
      "           4       0.58      0.58      0.58       675\n",
      "           5       0.57      0.54      0.55       901\n",
      "           6       0.43      0.42      0.42       390\n",
      "           7       0.43      0.48      0.45      1596\n",
      "           8       0.49      0.41      0.45      1862\n",
      "           9       0.37      0.42      0.39       738\n",
      "          10       0.55      0.41      0.47      2045\n",
      "          11       0.17      0.10      0.13       477\n",
      "          12       0.46      0.60      0.52       334\n",
      "\n",
      "    accuracy                           0.45     12750\n",
      "   macro avg       0.43      0.44      0.43     12750\n",
      "weighted avg       0.46      0.45      0.45     12750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load features and labels\n",
    "features_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Lab04\\extracted_features.npy'\n",
    "labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Lab04\\labels.npy'\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# For example, training a RandomForest Classifier to see the effect of SMOTE\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.38      0.32       408\n",
      "           1       0.45      0.51      0.48       936\n",
      "           2       0.41      0.47      0.44      1628\n",
      "           3       0.34      0.39      0.36       760\n",
      "           4       0.50      0.55      0.52       675\n",
      "           5       0.58      0.52      0.55       901\n",
      "           6       0.40      0.40      0.40       390\n",
      "           7       0.40      0.46      0.43      1596\n",
      "           8       0.44      0.37      0.40      1862\n",
      "           9       0.36      0.37      0.36       738\n",
      "          10       0.52      0.41      0.46      2045\n",
      "          11       0.17      0.10      0.13       477\n",
      "          12       0.50      0.57      0.53       334\n",
      "\n",
      "    accuracy                           0.43     12750\n",
      "   macro avg       0.41      0.42      0.41     12750\n",
      "weighted avg       0.43      0.43      0.43     12750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load features and labels\n",
    "features_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Reduced 512\\Features_reduced.npy'\n",
    "labels_path = 'D:\\SEM-4\\ML\\CODES\\Machine-Learning\\Reduced 512\\Labels_reduced.npy'\n",
    "features = np.load(features_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# For example, training a RandomForest Classifier to see the effect of SMOTE\n",
    "classifier = RandomForestClassifier(random_state=42)\n",
    "classifier.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
